{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "midi_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrVAiq4VUvlcZ+ZFI/4Jmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Djadih/DataScience_Project/blob/main/midi_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lStOspBHO1GT"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord, stream, tempo, meter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding,Dropout,LSTM,Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAr_0tSdO5H_"
      },
      "source": [
        " from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU1pL_3OO61m"
      },
      "source": [
        "def get_notes(filename):\n",
        "  buffer_size = 500000\n",
        "  notes = [''] * buffer_size\n",
        "  last_time = 0\n",
        "  offset = []\n",
        "  midi = converter.parse(filename)\n",
        "  print('parsing {}'.format(filename))\n",
        "  try: # file has instrument parts\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    notes_to_parse = s2.recurse() \n",
        "  except: # file has notes in a flat structure\n",
        "    notes_to_parse = midi.flat.notes\n",
        "  for element in notes_to_parse:\n",
        "    if isinstance(element, note.Note):\n",
        "      time = int(element.offset * 4)\n",
        "      if notes[time] == '':\n",
        "        notes[time] = str(element.pitch.midi)\n",
        "      last_time = time\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      time = int(element.offset * 4)\n",
        "      if notes[time] == '':\n",
        "        notes[time] = '.'.join(str(n) for n in element.normalOrder) \n",
        "      last_time = time\n",
        "  print(last_time)\n",
        "  return notes[:last_time]\n",
        "\n",
        "def prepare_sequences(notes, n_vocab, note_to_int):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 400\n",
        "    i  = []\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "    network_output = to_categorical(network_output)\n",
        "    return (network_input, normalized_input, network_output)\n",
        "\n",
        "def normalize(network_input, n_vocab):\n",
        "    sequence_length = 400\n",
        "    n_patterns = len(network_input)\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "    return normalized_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zn_AoSgO_7p"
      },
      "source": [
        "file_names = glob.glob(\"*.mid\")\n",
        "print(file_names)\n",
        "notes = []\n",
        "for song in file_names:\n",
        "    notes = notes + get_notes(song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZxD8MkBtpg5"
      },
      "source": [
        "n_vocab = len(set(notes))\n",
        "n_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEREDr15LX-u"
      },
      "source": [
        "# get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))  \n",
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UaMKAgiPDpt"
      },
      "source": [
        "network_input, normalized_input,  network_output = prepare_sequences(notes, n_vocab, note_to_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTBnIifBObi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(network_input, network_output, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daXqQFoDL036"
      },
      "source": [
        "X_train_normalized = normalize(X_train, n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryBtwszyHQJ6"
      },
      "source": [
        "X_train_normalized.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGo-kHkHPKHO"
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "    model.add(LSTM(256, return_sequences=True))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4-Xe4CPMm4"
      },
      "source": [
        "model = create_network(X_train_normalized, n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYuqnjUY2xv2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clVhyq6nPQaR"
      },
      "source": [
        "model.fit(X_train_normalized, y_train, epochs=100, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev9EnYneIgt5"
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    end = len(network_input)\n",
        "    start = np.random.randint(0, end)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttbDOxBGMsfv"
      },
      "source": [
        "output = generate_notes(model, X_test, pitchnames, n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkX8CyRWWxr"
      },
      "source": [
        "output[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_9zDh6eQVGD"
      },
      "source": [
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for idx, pattern in enumerate(prediction_output):\n",
        "      if len(pattern) != 0:\n",
        "        notes_in_chord = [int(n) for n in pattern.split('.')]\n",
        "        new_chord = chord.Chord(notes_in_chord)\n",
        "        new_chord.offset = idx/4\n",
        "        output_notes.append(new_chord)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0IclYN8Qgcf"
      },
      "source": [
        "create_midi(output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}